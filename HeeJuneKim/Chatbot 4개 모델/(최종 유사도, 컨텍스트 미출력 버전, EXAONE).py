# -*- coding: utf-8 -*-
"""
medical_main.py (V4.6: FriendliAI(EXAONE 32B)ë¡œ LLM êµì²´ + ì¶œë ¥ ê°„ì†Œí™” ìœ ì§€)
- í„°ë¯¸ë„ì— ì¶œë ¥ë˜ë˜ 1ì°¨ ê²€ìƒ‰ ê²°ê³¼(ìœ ì‚¬ë„)ì™€ LLM ì»¨í…ìŠ¤íŠ¸ ë¯¸ë¦¬ë³´ê¸°ë¥¼ ì œê±°.
- ì‚¬ìš©ìì—ê²ŒëŠ” AIì˜ ì§ˆë¬¸ê³¼ ìµœì¢… ë‹µë³€ë§Œ ë³´ì´ë„ë¡ ìœ ì§€.
- LLM í´ë¼ì´ì–¸íŠ¸: FriendliAI Serverless (OpenAI í˜¸í™˜) ì‚¬ìš©.
"""

# ------------------------------------------------------------
# 0) í‘œì¤€/ì„œë“œíŒŒí‹° ëª¨ë“ˆ ì„í¬íŠ¸
# ------------------------------------------------------------
import os, json, re                          # os: ê²½ë¡œ/í™˜ê²½ë³€ìˆ˜, json: íŒŒì¼ ì½ê¸°, re: ì •ê·œí‘œí˜„ì‹
from typing import List, Tuple               # íƒ€ì… íŒíŠ¸ìš©

# LangChain, OpenAI ë“± ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸
from langchain_huggingface import HuggingFaceEmbeddings  # í—ˆê¹…í˜ì´ìŠ¤ ì„ë² ë”© ëª¨ë“ˆ(ì‹ ê·œ íŒ¨í‚¤ì§€)
from langchain_community.vectorstores import FAISS       # FAISS ë²¡í„°DB
from openai import OpenAI                                # OpenAI í˜¸í™˜ í´ë¼ì´ì–¸íŠ¸(Friendliê°€ ì´ ì¸í„°í˜ì´ìŠ¤ ì§€ì›)

# .env íŒŒì¼ ë¡œë“œ (ì„ íƒ)
try:
    from dotenv import load_dotenv
    load_dotenv()                         # .envë¥¼ ì½ì–´ í™˜ê²½ë³€ìˆ˜ë¡œ ë“±ë¡(ì—†ì–´ë„ í†µê³¼)
except Exception:
    pass

# GPU ì„¤ì •: torchê°€ ìˆìœ¼ë©´ CUDA ì‚¬ìš©, ì—†ìœ¼ë©´ CPU ì‚¬ìš©
try:
    import torch
    DEVICE = "cuda" if torch.cuda.is_available() else "cpu"
except Exception:
    DEVICE = "cpu"


# ------------------------------------------------------------
# 1) ê²½ë¡œ/DB ê¸°ë³¸ ì„¤ì •
# ------------------------------------------------------------
JSON_FOLDER   = os.getenv("JSON_FOLDER", "./json_diseases_final_ver").strip()
_default_dbdir = f"vector_unified_{os.path.basename(JSON_FOLDER) or 'db'}"
DB_DIR         = os.getenv("DB_DIR", _default_dbdir).strip()

UNIFIED_DB_PATH  = f"{DB_DIR}/faiss_unified_disease_db"   # í†µí•© ì¸ë±ìŠ¤ ì €ì¥ ê²½ë¡œ
os.makedirs(DB_DIR, exist_ok=True)                        # í´ë”ê°€ ì—†ìœ¼ë©´ ìƒì„±


# ------------------------------------------------------------
# 2) ì‹¤í–‰ ì˜µì…˜ ë° ê¸°ì¤€ê°’(Threshold) ì„¤ì •
# ------------------------------------------------------------
FORCE_REBUILD    = os.getenv("FORCE_REBUILD", "0") == "1"   # 1ì´ë©´ í•­ìƒ ì¸ë±ìŠ¤ ì¬ìƒì„±
K_DISEASE    = int(os.getenv("K_DISEASE", "10"))            # ê²€ìƒ‰ ìƒìœ„ kê°œ ë¬¸ì„œ
MAX_DISEASES = int(os.getenv("MAX_DISEASES", "5"))          # LLMì— íˆ¬ì…í•  ìµœëŒ€ ë¬¸ì„œ ìˆ˜
CTX_CHARS    = int(os.getenv("CTX_CHARS", "4000"))          # LLMì— ì „ë‹¬í•  ì»¨í…ìŠ¤íŠ¸ ê¸¸ì´ ì œí•œ(ë¬¸ììˆ˜)

LOW_CONF_THRESHOLD = 0.5     # ë¹„ì˜ë£Œ/ì¼ë°˜ ì‘ë‹µ ë¼ìš°íŒ… ê¸°ì¤€
HIGH_CONF_THRESHOLD = 0.74   # í™•ì‹ ë„ ë†’ìŒ ê¸°ì¤€
SCORE_DIFF_THRESHOLD = 0.03  # ìƒìœ„ ê²°ê³¼ ê°„ ì ìˆ˜ ì°¨ì´ ê¸°ì¤€


# ------------------------------------------------------------
# 3) ì„ë² ë”© ëª¨ë¸ ì¤€ë¹„
# ------------------------------------------------------------
# ì£¼ì˜: E5 ê³„ì—´ ëª¨ë¸ì„ ì“¸ ê²½ìš° ì¿¼ë¦¬ì— "query: " ì ‘ë‘ì‚¬ê°€ ìœ ë¦¬í•©ë‹ˆë‹¤(ì•„ë˜ ê²€ìƒ‰ í•¨ìˆ˜ì—ì„œ ì ìš©).
#       í˜„ì¬ ê¸°ë³¸ê°’ì€ roberta ë©€í‹°íƒœìŠ¤í¬ì§€ë§Œ, í•„ìš” ì‹œ EMBED_MODEL_NAMEë§Œ ë°”ê¾¸ë©´ ë©ë‹ˆë‹¤.
EMBED_MODEL_NAME = os.getenv("EMBED_MODEL_NAME", "jhgan/ko-sroberta-multitask").strip()
embedding_model = HuggingFaceEmbeddings(
    model_name=EMBED_MODEL_NAME,                           # ì„ë² ë”© ëª¨ë¸ ì´ë¦„
    model_kwargs={"device": DEVICE},                       # GPU/CPU ì„¤ì •
    encode_kwargs={"normalize_embeddings": True, "batch_size": 64},  # ì •ê·œí™” + ë°°ì¹˜ í¬ê¸°
)


# ------------------------------------------------------------
# 4) FriendliAI LLM í´ë¼ì´ì–¸íŠ¸ ì¤€ë¹„ (OpenAI í˜¸í™˜)
# ------------------------------------------------------------
# Friendli Serverless OpenAI-í˜¸í™˜ ì—”ë“œí¬ì¸íŠ¸ & ëª¨ë¸ ì‹ë³„ì
FRIENDLI_BASE_URL = "https://api.friendli.ai/serverless/v1"
FRIENDLI_MODEL = os.getenv("FRIENDLI_MODEL", "LGAI-EXAONE/EXAONE-4.0.1-32B").strip()

# í† í°ì€ í™˜ê²½ë³€ìˆ˜ë¡œ ì£¼ì…(.env ë˜ëŠ” OS í™˜ê²½ë³€ìˆ˜)
FRIENDLI_TOKEN = os.getenv("FRIENDLI_TOKEN")
if not FRIENDLI_TOKEN:
    # ì‹¤í–‰ ì „ .envì— FRIENDLI_TOKEN=xxxx ì¶”ê°€ ë˜ëŠ” OS í™˜ê²½ë³€ìˆ˜ ë“±ë¡ í•„ìš”
    raise RuntimeError("í™˜ê²½ë³€ìˆ˜ FRIENDLI_TOKEN ì´(ê°€) ë¹„ì—ˆìŠµë‹ˆë‹¤. .env ë˜ëŠ” OS í™˜ê²½ë³€ìˆ˜ì— ì„¤ì •í•˜ì„¸ìš”.")

# OpenAI í˜¸í™˜ í´ë¼ì´ì–¸íŠ¸ ê°ì²´(ì´ë¦„ë§Œ OpenAI, ì‹¤ì œë¡œ Friendli ì„œë²„ì™€ í†µì‹ )
llm_client = OpenAI(
    api_key=FRIENDLI_TOKEN,       # Friendli ë°œê¸‰ í† í°
    base_url=FRIENDLI_BASE_URL,   # Friendli OpenAI í˜¸í™˜ ì„œë²„ URL
)

def chat_with_friendli(messages, **gen_opts) -> str:
    """
    FriendliAI Chat Completions í˜¸ì¶œ (OpenAI í˜¸í™˜)
    - messages: [{"role": "...", "content": "..."}]
    - gen_opts: temperature, max_tokens ë“±
    """
    completion = llm_client.chat.completions.create(
        model=FRIENDLI_MODEL,
        messages=messages,
        temperature=gen_opts.get("temperature", 0.3),
        max_tokens=gen_opts.get("max_tokens", 1024),
    )
    return completion.choices[0].message.content.strip()


# ------------------------------------------------------------
# 5) LLM ë³´ì¡° ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤
# ------------------------------------------------------------
def extract_any(section_val) -> str:
    """
    JSONì˜ ê° í•„ë“œ(ë¬¸ìì—´/ë¦¬ìŠ¤íŠ¸/ë”•ì…”ë„ˆë¦¬)ë¥¼ ì¼ê´€ë˜ê²Œ ë¬¸ìì—´ë¡œ í’€ì–´ë‚´ëŠ” í•¨ìˆ˜.
    - ì¦ìƒ.supplementê°€ ìˆìœ¼ë©´ ìš°ì„  í¬í•¨.
    - "None" ê°™ì€ ì“°ë ˆê¸° ë¬¸ìì—´ì€ ì œê±°.
    """
    if section_val is None:
        return ""
    if isinstance(section_val, dict):
        texts = []
        # supplementê°€ ìˆìœ¼ë©´ ë¨¼ì € í¼ì¹¨
        if 'supplement' in section_val:
            supp = section_val.get('supplement')
            if supp and isinstance(supp, list):
                texts.append("\n".join(str(x) for x in supp if x and str(x) != "None"))
        # ë‚˜ë¨¸ì§€ í‚¤/ê°’ë„ í¼ì¹¨
        for k, v in section_val.items():
            if k == 'supplement':
                continue
            if isinstance(v, list):
                texts.append("\n".join(str(x) for x in v if x and str(x) != "None"))
            elif v and str(v) != "None":
                texts.append(str(v))
        return "\n".join(texts).strip()
    if isinstance(section_val, list):
        return "\n".join(str(x) for x in section_val if x and str(x) != "None").strip()
    return str(section_val).strip()

def get_disease_from_doc(doc):
    """ FAISS ê²€ìƒ‰ ê²°ê³¼ ë¬¸ì„œì—ì„œ ë³‘ëª… ë©”íƒ€ë°ì´í„°ë¥¼ ì•ˆì „íˆ êº¼ë‚´ê¸° """
    return getattr(doc, "metadata", {}).get("ë³‘ëª…", "ì•Œ ìˆ˜ ì—†ëŠ” ì§ˆë³‘")

def extract_numbered_block(answer: str) -> str:
    """
    LLMì˜ ì „ì²´ ë‹µë³€ ì¤‘ '1. ... 2. ...' í˜•íƒœë¡œ ì‹œì‘í•˜ëŠ” ë²ˆí˜¸ ëª©ë¡ë§Œ ê¹”ë”íˆ ì¶”ì¶œ.
    í•­ëª©ì´ ë„ˆë¬´ ë§ìœ¼ë©´ 3~6ê°œë¡œ ì œí•œí•˜ì—¬ ê°„ê²°í™”.
    """
    items = re.findall(r'(?ms)^\s*\d\.\s.*?(?=^\s*\d\.|\Z)', answer)
    items = [it.strip() for it in items if it.strip()]
    if not items:
        return answer.strip()
    if len(items) >= 6:
        keep = items[:6]
    elif len(items) >= 5:
        keep = items[:5]
    elif len(items) >= 3:
        keep = items[:3]
    else:
        keep = items
    return "\n".join(keep).strip()


# ------------------------------------------------------------
# 6) FAISS í—¬í¼ ë° ë‹¨ì¼ ì¸ë±ìŠ¤ êµ¬ì¶• í•¨ìˆ˜
# ------------------------------------------------------------
def faiss_from_texts(texts, embedding_model, metadatas=None):
    """ LangChain ë²„ì „ì— ë”°ë¼ ì¸ìëª…ì´ ë‹¤ë¥¸ ì´ìŠˆë¥¼ try/exceptë¡œ ì–‘ìª½ ì§€ì› """
    try:
        return FAISS.from_texts(texts, embedding=embedding_model, metadatas=metadatas)
    except TypeError:
        return FAISS.from_texts(texts, embeddings=embedding_model, metadatas=metadatas)

def faiss_load_local(path, embedding_model):
    """ ì €ì¥ëœ ë¡œì»¬ ì¸ë±ìŠ¤ë¥¼ ì•ˆì „í•˜ê²Œ ë¡œë“œ(ì—­ì§ë ¬í™” í—ˆìš©) """
    try:
        return FAISS.load_local(path, embedding=embedding_model, allow_dangerous_deserialization=True)
    except TypeError:
        return FAISS.load_local(path, embeddings=embedding_model, allow_dangerous_deserialization=True)

def _index_file(path: str) -> str:
    return os.path.join(path, "index.faiss")

def _latest_json_mtime(folder: str) -> float:
    """ í´ë” ë‚´ JSON íŒŒì¼ë“¤ì˜ ë§ˆì§€ë§‰ ìˆ˜ì •ì‹œê° ì¤‘ ìµœëŒ“ê°’ """
    times = []
    if not os.path.isdir(folder):
        return 0.0
    for f in os.listdir(folder):
        if f.lower().endswith(".json"):
            times.append(os.path.getmtime(os.path.join(folder, f)))
    return max(times) if times else 0.0

def _needs_rebuild(index_path: str, source_folder: str) -> bool:
    """ ì¸ë±ìŠ¤ê°€ ì—†ê±°ë‚˜, ë°ì´í„°ê°€ ë” ìµœì‹ ì´ë©´ ì¬ë¹Œë“œ í•„ìš” """
    if FORCE_REBUILD:
        return True
    idx = _index_file(index_path)
    if not os.path.exists(idx):
        return True
    return os.path.getmtime(idx) < _latest_json_mtime(source_folder)

def build_or_load_unified_disease_db():
    """
    í†µí•© ì§ˆë³‘ ì¸ë±ìŠ¤ ìƒì„±/ë¡œë”©:
    - ê²€ìƒ‰ ì •í™•ë„ë¥¼ ìœ„í•´ 'ì¦ìƒ'ê³¼ 'ì¦ìƒ.supplement' ê°€ì¤‘ì¹˜ ë°˜ì˜
    - LLM í”„ë¡¬í”„íŠ¸ì—ëŠ” 'clean_text'(ê°€ì¤‘ì¹˜ ì—†ëŠ” í´ë¦° ë²„ì „) ì‚¬ìš©
    """
    if _needs_rebuild(UNIFIED_DB_PATH, JSON_FOLDER):
        print("[Rebuild] í†µí•© ì§ˆë³‘ ì¸ë±ìŠ¤ (ê²€ìƒ‰ìš©/LLMìš© ë¶„ë¦¬)ë¥¼ ìƒˆë¡œ ìƒì„±í•©ë‹ˆë‹¤.")
        texts_for_embedding, metas = [], []
        files = sorted([f for f in os.listdir(JSON_FOLDER) if f.endswith(".json")])

        for filename in files:
            with open(os.path.join(JSON_FOLDER, filename), encoding="utf-8") as f:
                data = json.load(f)

            disease_name = (data.get("ë³‘ëª…") or "").strip()
            if not disease_name:
                continue

            symptom_data = data.get("ì¦ìƒ", {})
            symptom_text = extract_any(symptom_data)

            # ì¦ìƒ.supplementë¥¼ ë³„ë„ë¡œ ì¶”ì¶œ(ììœ ìì—°ì–´ í‘œí˜„ ë³´ê°•)
            supplement_text = ""
            if isinstance(symptom_data, dict) and 'supplement' in symptom_data:
                supplement_text = extract_any(symptom_data.get('supplement'))

            # (ê²€ìƒ‰ìš©) ì¦ìƒ/ë³´ì¶©ì„ 3ë°° ê°€ì¤‘ì¹˜ë¡œ í™•ì¥í•˜ì—¬ í¬í•¨
            weighted_symptom_part = (f"[ì¦ìƒ] {symptom_text}\n" + f"[ì¦ìƒ.supplement] {supplement_text}\n") * 3

            # ë‚˜ë¨¸ì§€ í•„ë“œ(ì •ì˜/ì›ì¸/ì§„ë‹¨/ì¹˜ë£Œ ë“±)
            other_info_parts = [f"[ë³‘ëª…] {disease_name}"]
            for key, value in data.items():
                if key not in ["ë³‘ëª…", "ì¦ìƒ"]:
                    content = extract_any(value)
                    if content:
                        other_info_parts.append(f"[{key}] {content}")
            other_info_part = "\n".join(other_info_parts)

            # (ê²€ìƒ‰ìš©) ê°€ì¤‘ì¹˜ê°€ ì ìš©ëœ ì „ì²´ í…ìŠ¤íŠ¸
            weighted_document_text = (weighted_symptom_part + other_info_part).strip()
            texts_for_embedding.append(weighted_document_text)

            # (LLMìš©) ê°€ì¤‘ì¹˜ ì—†ëŠ” í´ë¦° í…ìŠ¤íŠ¸ë¥¼ ë©”íƒ€ë°ì´í„°ì— ë³´ê´€
            clean_symptom_part = f"[ì¦ìƒ] {symptom_text}"
            clean_document_text = (clean_symptom_part + "\n" + other_info_part).strip()
            metas.append({"ë³‘ëª…": disease_name, "íŒŒì¼": filename, "clean_text": clean_document_text})

        if not texts_for_embedding:
            raise RuntimeError("í†µí•© ì¸ë±ìŠ¤ë¥¼ ë§Œë“¤ í…ìŠ¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")

        db = faiss_from_texts(texts_for_embedding, embedding_model, metadatas=metas)
        db.save_local(UNIFIED_DB_PATH)
        return db
    else:
        print("[Load] ê¸°ì¡´ í†µí•© ì§ˆë³‘ ì¸ë±ìŠ¤ë¥¼ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤.")
        return faiss_load_local(UNIFIED_DB_PATH, embedding_model)


# ------------------------------------------------------------
# 7) ë‹¨ì¼ ê²€ìƒ‰ í•¨ìˆ˜
# ------------------------------------------------------------
def search_unified_db_with_scores(db, user_query: str, k: int) -> List[Tuple[any, float]]:
    """
    ì§ˆì˜ì–´ë¥¼ ë°›ì•„ ìƒìœ„ kê°œ ë¬¸ì„œì™€ ê±°ë¦¬ ì ìˆ˜ë¥¼ í•¨ê»˜ ë°˜í™˜.
    - E5 ëª¨ë¸ì„ ê³ ë ¤í•˜ì—¬ 'query: ' ì ‘ë‘ì‚¬ë¥¼ ë¶™ì„(ë‹¤ë¥¸ ëª¨ë¸ì´ì–´ë„ í° ë¬¸ì œ ì—†ìŒ)
    - FAISSëŠ” ê±°ë¦¬(ì‘ì„ìˆ˜ë¡ ìœ ì‚¬), ìš°ë¦¬ëŠ” ì•„ë˜ì—ì„œ ê°„ë‹¨íˆ ìœ ì‚¬ë„ ì ìˆ˜ë¡œ ë³€í™˜í•´ ì‚¬ìš©.
    """
    q_fmt = f"query: {user_query}"
    if not db:
        return []
    return db.similarity_search_with_score(q_fmt, k)


# ------------------------------------------------------------
# 8) í”„ë¡¬í”„íŠ¸(SYSTEM) ë° ë©”ì¸ ë£¨í”„
# ------------------------------------------------------------
SYSTEM_PROMPT = """
ë‹¹ì‹ ì€ ì˜ë£Œ ìƒë‹´ ì±—ë´‡ì…ë‹ˆë‹¤.
ì‚¬ìš©ì ì§ˆë¬¸ì´ ê±´ê°•/ì¦ìƒ/ì˜í•™ ê´€ë ¨ì´ë©´, ì•„ë˜ [ì§ˆë³‘ ì •ë³´]ë¥¼ ì°¸ê³ í•˜ì—¬ 'ì¶œë ¥ í˜•ì‹'ì— ë§ì¶° ë‹µë³€í•˜ì„¸ìš”.
'ìƒë¹„ì•½ ì¶”ì²œ'ì€ ë‹¹ì‹ ì˜ ì˜ë£Œ ì§€ì‹ì„ ë°”íƒ•ìœ¼ë¡œ ë‹µë³€í•´ì•¼ í•©ë‹ˆë‹¤.
ë¶ˆí•„ìš”í•œ ì„œë¡ /ê²°ë¡  ì—†ì´ 'ì¶œë ¥ í˜•ì‹'ì˜ í•­ëª©ë§Œ ê°„ê²°í•˜ê²Œ ë‹µë³€í•˜ì„¸ìš”.

ì¶œë ¥ í˜•ì‹:
1. ì˜ˆìƒë˜ëŠ” ë³‘ëª… (2~3ê°€ì§€):
   - ì²« ë²ˆì§¸ ë³‘ëª…ì€ **êµµê²Œ** í‘œê¸°í•˜ê³  ê°„ë‹¨í•œ ì„¤ëª…ë„ í¬í•¨í•˜ì„¸ìš”.
2. ì£¼ìš” ì›ì¸:
3. ì¶”ì²œ ì§„ë£Œê³¼ (2~3ê³¼):
4. ì˜ˆë°© ë° ê´€ë¦¬ ë°©ë²•:
5. ìƒí™œ ì‹œ ì£¼ì˜ì‚¬í•­:
6. ìƒë¹„ì•½ ì¶”ì²œ(ì‹¤ì œ ì œí’ˆ):
""".strip()

if __name__ == "__main__":
    # 1) ì¸ë±ìŠ¤ ì¤€ë¹„
    disease_db = build_or_load_unified_disease_db()
    print("\nâœ… í†µí•© ì¸ë±ìŠ¤ ì¤€ë¹„ ì™„ë£Œ")

    # 2) ëŒ€í™” ë£¨í”„
    while True:
        user_input = input("\nğŸ©º ì¦ìƒì„ ì…ë ¥í•˜ì„¸ìš” (ì¢…ë£Œ: exit): ").strip()
        if user_input.lower() in ["exit", "ì¢…ë£Œ", "quit"]:
            print("ì±—ë´‡ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
            break

        # 2-1) ê²€ìƒ‰ ìˆ˜í–‰
        docs_with_scores = search_unified_db_with_scores(disease_db, user_input, k=K_DISEASE)

        # 2-2) ê²€ìƒ‰ ì‹¤íŒ¨ ì‹œ: ì¼ë°˜ ì–´ì‹œìŠ¤í„´íŠ¸ ì‘ë‹µ
        if not docs_with_scores:
            print("[Info] ê´€ë ¨ ì§ˆë³‘ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì¼ë°˜ì ì¸ ë‹µë³€ì„ ì‹œë„í•©ë‹ˆë‹¤.")
            general_messages = [
                {"role": "system", "content": "ë‹¹ì‹ ì€ ì‚¬ìš©ìì—ê²Œ ì¹œì ˆí•˜ê²Œ ë‹µë³€í•˜ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤."},
                {"role": "user", "content": user_input},
            ]
            try:
                answer = chat_with_friendli(general_messages)
                print(f"\nğŸ§¾ [EXAONE 32B ë‹µë³€]\n{answer}")
            except Exception as e:
                print(f"[ì˜¤ë¥˜] API í˜¸ì¶œ ì‹¤íŒ¨: {e}")
            continue

        # 2-3) ê±°ë¦¬ â†’ ê°„ì´ ìœ ì‚¬ë„(1/(1+dist))ë¡œ ë³€í™˜
        docs_with_sim_scores = [(doc, 1 / (1 + score)) for doc, score in docs_with_scores]
        unique_docs = docs_with_sim_scores

        # (ì¶œë ¥ ê°„ì†Œí™”ë¡œ 1ì°¨ ê²€ìƒ‰ ê²°ê³¼/ì ìˆ˜ ë¯¸ë¦¬ë³´ê¸°ëŠ” ë¹„ë…¸ì¶œ)
        # print("\n--- [1ì°¨ ê²€ìƒ‰ ê²°ê³¼ (Top 3)] ---")
        # ...

        # 2-4) ìƒìœ„ 1ê°œ ìœ ì‚¬ë„ ì ìˆ˜ë¡œ ë¼ìš°íŒ… íŒë‹¨
        top1_doc, top1_score = unique_docs[0]
        final_docs = []

        # (A) ë¹„ì˜ë£Œ/ì¡ë‹´ ë¼ìš°íŒ…
        if top1_score < LOW_CONF_THRESHOLD:
            print(f"[íŒë‹¨] ë¹„ì˜ë£Œ ì§ˆë¬¸ (ìœ ì‚¬ë„: {top1_score:.2f} < {LOW_CONF_THRESHOLD})")
            general_messages = [
                {"role": "system", "content": "ë‹¹ì‹ ì€ ì‚¬ìš©ìì—ê²Œ ì¹œì ˆí•˜ê²Œ ë‹µë³€í•˜ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤."},
                {"role": "user", "content": user_input},
            ]
            try:
                answer = chat_with_friendli(general_messages)
                print(f"\nğŸ§¾ [EXAONE 32B ë‹µë³€]\n{answer}")
            except Exception as e:
                print(f"[ì˜¤ë¥˜] API í˜¸ì¶œ ì‹¤íŒ¨: {e}")
            continue

        # (B) í™•ì‹ ë„ íŒë‹¨
        is_confident = (
            top1_score >= HIGH_CONF_THRESHOLD
            and (len(unique_docs) < 3 or (unique_docs[0][1] - unique_docs[2][1]) >= SCORE_DIFF_THRESHOLD)
        )

        if is_confident:
            print(f"[íŒë‹¨] í™•ì‹ ë„ ë†’ìŒ (ìœ ì‚¬ë„: {top1_score:.2f})")
            final_docs = [doc for doc, score in unique_docs[:MAX_DISEASES]]
        else:
            # (C) í™•ì‹ ë„ ë‚®ìŒ â†’ ì¶”ê°€ ì¦ìƒ ìš”ì²­ í›„ ì¬ê²€ìƒ‰
            print(f"[íŒë‹¨] í™•ì‹ ë„ ë‚®ìŒ (ìœ ì‚¬ë„: {top1_score:.2f}). ì¶”ê°€ ì¦ìƒì„ ìš”ì²­í•©ë‹ˆë‹¤.")
            print(f"\nì¦ìƒì„ ì¡°ê¸ˆ ë” êµ¬ì²´ì ìœ¼ë¡œ ì•Œë ¤ì£¼ì‹œê² ì–´ìš”? ì¶”ê°€ì ì¸ ì¦ìƒì´ ìˆë‹¤ë©´ í•¨ê»˜ ì…ë ¥í•´ì£¼ì„¸ìš”.")
            user_answer = input("[ì¶”ê°€ ì¦ìƒ ì…ë ¥]: ").strip()

            if user_answer:
                combined_input = f"{user_input}\nì¶”ê°€ ì •ë³´: {user_answer}"
                print("\n[Info] ì¶”ê°€ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹¤ì‹œ ê²€ìƒ‰í•©ë‹ˆë‹¤...")
                final_search_res = search_unified_db_with_scores(disease_db, combined_input, k=K_DISEASE)
                final_docs = [doc for doc, score in final_search_res[:MAX_DISEASES]]
            else:
                print("[Info] ì¶”ê°€ ì…ë ¥ì´ ì—†ì–´ ì´ˆê¸° ê²€ìƒ‰ ê²°ê³¼ë¡œ ë‹µë³€ì„ ìƒì„±í•©ë‹ˆë‹¤.")
                final_docs = [doc for doc, score in unique_docs[:MAX_DISEASES]]

        # 2-5) LLM ìƒì„±: ê²€ìƒ‰ ì»¨í…ìŠ¤íŠ¸(í´ë¦° ë²„ì „) + ì‚¬ìš©ì ì§ˆë¬¸
        if final_docs:
            final_context = "\n---\n".join([doc.metadata.get('clean_text', doc.page_content) for doc in final_docs])
            final_user_input = user_input
            if 'combined_input' in locals() and 'user_answer' in locals() and user_answer:
                final_user_input = combined_input

            messages = [
                {"role": "system", "content": SYSTEM_PROMPT},
                {"role": "user", "content": f"[ì§ˆë³‘ ì°¸ê³ ]\n{final_context[:CTX_CHARS]}"},
                {"role": "user", "content": final_user_input},
            ]

            # (ì¶œë ¥ ê°„ì†Œí™”ë¡œ LLM ì»¨í…ìŠ¤íŠ¸ ë¯¸ë¦¬ë³´ê¸°ëŠ” ë¹„ë…¸ì¶œ)
            try:
                answer = chat_with_friendli(messages)
                print("\nğŸ§¾ [EXAONE 32B ìµœì¢… ë‹µë³€]")
                print(extract_numbered_block(answer))
            except Exception as e:
                print(f"[ì˜¤ë¥˜] ìµœì¢… ë‹µë³€ ìƒì„± ì‹¤íŒ¨: {e}")
