# -*- coding: utf-8 -*-
"""
medical_main.py (V4.5: ì¶œë ¥ ê°„ì†Œí™”)
- í„°ë¯¸ë„ì— ì¶œë ¥ë˜ë˜ 1ì°¨ ê²€ìƒ‰ ê²°ê³¼(ìœ ì‚¬ë„)ì™€ LLM ì»¨í…ìŠ¤íŠ¸ ë¯¸ë¦¬ë³´ê¸°ë¥¼ ì œê±°.
- ì‚¬ìš©ìì—ê²ŒëŠ” AIì˜ ì§ˆë¬¸ê³¼ ìµœì¢… ë‹µë³€ë§Œ ë³´ì´ë„ë¡ ìˆ˜ì •.
"""

# ------------------------------------------------------------
# 0) í‘œì¤€/ì„œë“œíŒŒí‹° ëª¨ë“ˆ ì„í¬íŠ¸
# ------------------------------------------------------------
import os, json, re
from typing import List, Tuple

# LangChain, OpenAI ë“± ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_community.vectorstores import FAISS
from openai import OpenAI

# .env íŒŒì¼ ë¡œë“œ (ì„ íƒ)
try:
    from dotenv import load_dotenv
    load_dotenv()
except Exception:
    pass

# GPU ì„¤ì •
try:
    import torch
    DEVICE = "cuda" if torch.cuda.is_available() else "cpu"
except Exception:
    DEVICE = "cpu"


# ------------------------------------------------------------
# 1) ê²½ë¡œ/DB ê¸°ë³¸ ì„¤ì •
# ------------------------------------------------------------
JSON_FOLDER   = os.getenv("JSON_FOLDER", "./json_diseases_final_ver").strip()
_default_dbdir = f"vector_unified_{os.path.basename(JSON_FOLDER) or 'db'}"
DB_DIR         = os.getenv("DB_DIR", _default_dbdir).strip()

UNIFIED_DB_PATH  = f"{DB_DIR}/faiss_unified_disease_db"
os.makedirs(DB_DIR, exist_ok=True)


# ------------------------------------------------------------
# 2) ì‹¤í–‰ ì˜µì…˜ ë° ê¸°ì¤€ê°’(Threshold) ì„¤ì •
# ------------------------------------------------------------
FORCE_REBUILD    = os.getenv("FORCE_REBUILD", "0") == "1"
K_DISEASE    = int(os.getenv("K_DISEASE", "10"))
MAX_DISEASES = int(os.getenv("MAX_DISEASES", "5"))
CTX_CHARS    = int(os.getenv("CTX_CHARS", "4000"))

LOW_CONF_THRESHOLD = 0.5
HIGH_CONF_THRESHOLD = 0.74
SCORE_DIFF_THRESHOLD = 0.03


# ------------------------------------------------------------
# 3) ì„ë² ë”© ëª¨ë¸ ë° A.X í´ë¼ì´ì–¸íŠ¸ ì¤€ë¹„
# ------------------------------------------------------------
EMBED_MODEL_NAME = os.getenv("EMBED_MODEL_NAME", "jhgan/ko-sroberta-multitask").strip()
embedding_model = HuggingFaceEmbeddings(
    model_name=EMBED_MODEL_NAME,
    model_kwargs={"device": DEVICE},
    encode_kwargs={"normalize_embeddings": True, "batch_size": 64},
)

AX_BASE_URL = os.getenv("AX_BASE_URL", "https://guest-api.sktax.chat/v1").strip()
AX_API_KEY  = os.getenv("ADOTX_API_KEY", "").strip()
AX_MODEL    = os.getenv("AX_MODEL", "ax4").strip()
if not AX_API_KEY:
    raise RuntimeError("í™˜ê²½ë³€ìˆ˜ ADOTX_API_KEYê°€ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤.")
client = OpenAI(base_url=AX_BASE_URL, api_key=AX_API_KEY)


# ------------------------------------------------------------
# 4) LLM í˜¸ì¶œ ë° ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜
# ------------------------------------------------------------
def chat_with_ax(messages, **gen_opts):
    completion = client.chat.completions.create(
        model=AX_MODEL,
        messages=messages,
        temperature=gen_opts.get("temperature", 0.3),
        max_tokens=gen_opts.get("max_tokens", 1024),
    )
    return completion.choices[0].message.content.strip()

def extract_any(section_val) -> str:
    if section_val is None: return ""
    if isinstance(section_val, dict):
        texts = []
        if 'supplement' in section_val:
            supp = section_val.get('supplement')
            if supp and isinstance(supp, list): texts.append("\n".join(str(x) for x in supp if x and str(x) != "None"))
        for k, v in section_val.items():
            if k == 'supplement': continue
            if isinstance(v, list): texts.append("\n".join(str(x) for x in v if x and str(x) != "None"))
            elif v and str(v) != "None": texts.append(str(v))
        return "\n".join(texts).strip()
    if isinstance(section_val, list): return "\n".join(str(x) for x in section_val if x and str(x) != "None").strip()
    return str(section_val).strip()

def get_disease_from_doc(doc):
    return getattr(doc, "metadata", {}).get("ë³‘ëª…", "ì•Œ ìˆ˜ ì—†ëŠ” ì§ˆë³‘")

def extract_numbered_block(answer: str) -> str:
    items = re.findall(r'(?ms)^\s*\d\.\s.*?(?=^\s*\d\.|\Z)', answer)
    items = [it.strip() for it in items if it.strip()]
    if not items: return answer.strip()
    if len(items) >= 6:   keep = items[:6]
    elif len(items) >= 5: keep = items[:5]
    elif len(items) >= 3: keep = items[:3]
    else:                 keep = items
    return "\n".join(keep).strip()


# ------------------------------------------------------------
# 5) FAISS í—¬í¼ ë° ë‹¨ì¼ ì¸ë±ìŠ¤ êµ¬ì¶• í•¨ìˆ˜
# ------------------------------------------------------------
def faiss_from_texts(texts, embedding_model, metadatas=None):
    try: return FAISS.from_texts(texts, embedding=embedding_model, metadatas=metadatas)
    except TypeError: return FAISS.from_texts(texts, embeddings=embedding_model, metadatas=metadatas)

def faiss_load_local(path, embedding_model):
    try: return FAISS.load_local(path, embedding=embedding_model, allow_dangerous_deserialization=True)
    except TypeError: return FAISS.load_local(path, embeddings=embedding_model, allow_dangerous_deserialization=True)

def _index_file(path: str) -> str: return os.path.join(path, "index.faiss")
def _latest_json_mtime(folder: str) -> float:
    times = []
    if not os.path.isdir(folder): return 0.0
    for f in os.listdir(folder):
        if f.lower().endswith(".json"): times.append(os.path.getmtime(os.path.join(folder, f)))
    return max(times) if times else 0.0
def _needs_rebuild(index_path: str, source_folder: str) -> bool:
    if FORCE_REBUILD: return True
    idx = _index_file(index_path)
    if not os.path.exists(idx): return True
    return os.path.getmtime(idx) < _latest_json_mtime(source_folder)

def build_or_load_unified_disease_db():
    if _needs_rebuild(UNIFIED_DB_PATH, JSON_FOLDER):
        print("[Rebuild] í†µí•© ì§ˆë³‘ ì¸ë±ìŠ¤ (ê²€ìƒ‰ìš©/LLMìš© ë¶„ë¦¬)ë¥¼ ìƒˆë¡œ ìƒì„±í•©ë‹ˆë‹¤.")
        texts_for_embedding, metas = [], []
        files = sorted([f for f in os.listdir(JSON_FOLDER) if f.endswith(".json")])
        
        for filename in files:
            with open(os.path.join(JSON_FOLDER, filename), encoding="utf-8") as f: data = json.load(f)
            
            disease_name = (data.get("ë³‘ëª…") or "").strip()
            if not disease_name: continue

            symptom_data = data.get("ì¦ìƒ", {})
            symptom_text = extract_any(symptom_data)
            
            supplement_text = ""
            if isinstance(symptom_data, dict) and 'supplement' in symptom_data:
                supplement_text = extract_any(symptom_data.get('supplement'))

            weighted_symptom_part = (f"[ì¦ìƒ] {symptom_text}\n" + f"[ì¦ìƒ.supplement] {supplement_text}\n") * 3

            other_info_parts = [f"[ë³‘ëª…] {disease_name}"]
            for key, value in data.items():
                if key not in ["ë³‘ëª…", "ì¦ìƒ"]:
                    content = extract_any(value)
                    if content: other_info_parts.append(f"[{key}] {content}")
            other_info_part = "\n".join(other_info_parts)
            
            weighted_document_text = (weighted_symptom_part + other_info_part).strip()
            texts_for_embedding.append(weighted_document_text)

            clean_symptom_part = f"[ì¦ìƒ] {symptom_text}"
            clean_document_text = (clean_symptom_part + "\n" + other_info_part).strip()
            
            metas.append({"ë³‘ëª…": disease_name, "íŒŒì¼": filename, "clean_text": clean_document_text})

        if not texts_for_embedding: raise RuntimeError("í†µí•© ì¸ë±ìŠ¤ë¥¼ ë§Œë“¤ í…ìŠ¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
        
        db = faiss_from_texts(texts_for_embedding, embedding_model, metadatas=metas)
        db.save_local(UNIFIED_DB_PATH); return db
    else:
        print("[Load] ê¸°ì¡´ í†µí•© ì§ˆë³‘ ì¸ë±ìŠ¤ë¥¼ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤.")
        return faiss_load_local(UNIFIED_DB_PATH, embedding_model)

# ------------------------------------------------------------
# 6) ë‹¨ì¼ ê²€ìƒ‰ í•¨ìˆ˜
# ------------------------------------------------------------
def search_unified_db_with_scores(db, user_query: str, k: int) -> List[Tuple[any, float]]:
    q_fmt = f"query: {user_query}"
    if not db: return []
    return db.similarity_search_with_score(q_fmt, k)


# ------------------------------------------------------------
# 7) ë©”ì¸ ë£¨í”„
# ------------------------------------------------------------
SYSTEM_PROMPT = """
ë‹¹ì‹ ì€ ì˜ë£Œ ìƒë‹´ ì±—ë´‡ì…ë‹ˆë‹¤.
ì‚¬ìš©ì ì§ˆë¬¸ì´ ê±´ê°•/ì¦ìƒ/ì˜í•™ ê´€ë ¨ì´ë©´, ì•„ë˜ [ì§ˆë³‘ ì •ë³´]ë¥¼ ì°¸ê³ í•˜ì—¬ 'ì¶œë ¥ í˜•ì‹'ì— ë§ì¶° ë‹µë³€í•˜ì„¸ìš”.
'ìƒë¹„ì•½ ì¶”ì²œ'ì€ ë‹¹ì‹ ì˜ ì˜ë£Œ ì§€ì‹ì„ ë°”íƒ•ìœ¼ë¡œ ë‹µë³€í•´ì•¼ í•©ë‹ˆë‹¤.
ë¶ˆí•„ìš”í•œ ì„œë¡ /ê²°ë¡  ì—†ì´ 'ì¶œë ¥ í˜•ì‹'ì˜ í•­ëª©ë§Œ ê°„ê²°í•˜ê²Œ ë‹µë³€í•˜ì„¸ìš”.

ì¶œë ¥ í˜•ì‹:
1. ì˜ˆìƒë˜ëŠ” ë³‘ëª… (2~3ê°€ì§€):
   - ì²« ë²ˆì§¸ ë³‘ëª…ì€ **êµµê²Œ** í‘œê¸°í•˜ê³  ê°„ë‹¨í•œ ì„¤ëª…ë„ í¬í•¨í•˜ì„¸ìš”.
2. ì£¼ìš” ì›ì¸:
3. ì¶”ì²œ ì§„ë£Œê³¼ (2~3ê³¼):
4. ì˜ˆë°© ë° ê´€ë¦¬ ë°©ë²•:
5. ìƒí™œ ì‹œ ì£¼ì˜ì‚¬í•­:
6. ìƒë¹„ì•½ ì¶”ì²œ(ì‹¤ì œ ì œí’ˆ):
""".strip()

if __name__ == "__main__":
    disease_db = build_or_load_unified_disease_db()
    print("\nâœ… í†µí•© ì¸ë±ìŠ¤ ì¤€ë¹„ ì™„ë£Œ")

    while True:
        user_input = input("\nğŸ©º ì¦ìƒì„ ì…ë ¥í•˜ì„¸ìš” (ì¢…ë£Œ: exit): ").strip()
        if user_input.lower() in ["exit", "ì¢…ë£Œ", "quit"]:
            print("ì±—ë´‡ì„ ì¢…ë£Œí•©ë‹ˆë‹¤."); break
        
        docs_with_scores = search_unified_db_with_scores(disease_db, user_input, k=K_DISEASE)
        
        if not docs_with_scores:
            print("[Info] ê´€ë ¨ ì§ˆë³‘ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì¼ë°˜ì ì¸ ë‹µë³€ì„ ì‹œë„í•©ë‹ˆë‹¤.")
            general_messages = [{"role": "system", "content": "ë‹¹ì‹ ì€ ì‚¬ìš©ìì—ê²Œ ì¹œì ˆí•˜ê²Œ ë‹µë³€í•˜ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤."}, {"role": "user", "content": user_input}]
            try:
                answer = chat_with_ax(general_messages)
                print(f"\nğŸ§¾ [A.X 4.0 ë‹µë³€]\n{answer}")
            except Exception as e: print(f"[ì˜¤ë¥˜] API í˜¸ì¶œ ì‹¤íŒ¨: {e}")
            continue

        docs_with_sim_scores = [(doc, 1 / (1 + score)) for doc, score in docs_with_scores]
        unique_docs = docs_with_sim_scores
        
        # â˜…â˜…â˜… ìˆ˜ì •ëœ ë¶€ë¶„: ìœ ì‚¬ë„ ì ìˆ˜ ì¶œë ¥ì„ ì£¼ì„ ì²˜ë¦¬ â˜…â˜…â˜…
        # print("\n--- [1ì°¨ ê²€ìƒ‰ ê²°ê³¼ (Top 3)] ---")
        # for doc, score in unique_docs[:3]:
        #     print(f"  - ìœ ì‚¬ë„: {score:.4f} / ì§ˆë³‘ëª…: {get_disease_from_doc(doc)}")
        # print("---------------------------------")
        
        top1_doc, top1_score = unique_docs[0]
        final_docs = []

        if top1_score < LOW_CONF_THRESHOLD:
            print(f"[íŒë‹¨] ë¹„ì˜ë£Œ ì§ˆë¬¸ (ìœ ì‚¬ë„: {top1_score:.2f} < {LOW_CONF_THRESHOLD})")
            general_messages = [{"role": "system", "content": "ë‹¹ì‹ ì€ ì‚¬ìš©ìì—ê²Œ ì¹œì ˆí•˜ê²Œ ë‹µë³€í•˜ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤."}, {"role": "user", "content": user_input}]
            try:
                answer = chat_with_ax(general_messages)
                print(f"\nğŸ§¾ [A.X 4.0 ë‹µë³€]\n{answer}")
            except Exception as e:
                print(f"[ì˜¤ë¥˜] API í˜¸ì¶œ ì‹¤íŒ¨: {e}")
            continue

        is_confident = top1_score >= HIGH_CONF_THRESHOLD and \
                       (len(unique_docs) < 3 or (unique_docs[0][1] - unique_docs[2][1]) >= SCORE_DIFF_THRESHOLD)
        
        if is_confident:
            print(f"[íŒë‹¨] í™•ì‹ ë„ ë†’ìŒ (ìœ ì‚¬ë„: {top1_score:.2f})")
            final_docs = [doc for doc, score in unique_docs[:MAX_DISEASES]]
        else:
            print(f"[íŒë‹¨] í™•ì‹ ë„ ë‚®ìŒ (ìœ ì‚¬ë„: {top1_score:.2f}). ì¶”ê°€ ì¦ìƒì„ ìš”ì²­í•©ë‹ˆë‹¤.")
            print(f"\nì¦ìƒì„ ì¡°ê¸ˆ ë” êµ¬ì²´ì ìœ¼ë¡œ ì•Œë ¤ì£¼ì‹œê² ì–´ìš”? ì¶”ê°€ì ì¸ ì¦ìƒì´ ìˆë‹¤ë©´ í•¨ê»˜ ì…ë ¥í•´ì£¼ì„¸ìš”.")
            user_answer = input("[ì¶”ê°€ ì¦ìƒ ì…ë ¥]: ").strip()
            
            if user_answer:
                combined_input = f"{user_input}\nì¶”ê°€ ì •ë³´: {user_answer}"
                print("\n[Info] ì¶”ê°€ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹¤ì‹œ ê²€ìƒ‰í•©ë‹ˆë‹¤...")
                final_search_res = search_unified_db_with_scores(disease_db, combined_input, k=K_DISEASE)
                final_docs = [doc for doc, score in final_search_res[:MAX_DISEASES]]
            else:
                print("[Info] ì¶”ê°€ ì…ë ¥ì´ ì—†ì–´ ì´ˆê¸° ê²€ìƒ‰ ê²°ê³¼ë¡œ ë‹µë³€ì„ ìƒì„±í•©ë‹ˆë‹¤.")
                final_docs = [doc for doc, score in unique_docs[:MAX_DISEASES]]

        if final_docs:
            final_context = "\n---\n".join([doc.metadata.get('clean_text', doc.page_content) for doc in final_docs])
            final_user_input = user_input
            if 'combined_input' in locals() and 'user_answer' in locals() and user_answer:
                final_user_input = combined_input

            messages = [
                {"role": "system", "content": SYSTEM_PROMPT},
                {"role": "user", "content": f"[ì§ˆë³‘ ì°¸ê³ ]\n{final_context[:CTX_CHARS]}"},
                {"role": "user", "content": final_user_input},
            ]
            
            # â˜…â˜…â˜… ìˆ˜ì •ëœ ë¶€ë¶„: ì»¨í…ìŠ¤íŠ¸ ë¯¸ë¦¬ë³´ê¸° ì¶œë ¥ì„ ì£¼ì„ ì²˜ë¦¬ â˜…â˜…â˜…
            # print("\nğŸ§© [LLM ì»¨í…ìŠ¤íŠ¸ ë¯¸ë¦¬ë³´ê¸° (í´ë¦° ë²„ì „)]")
            # print(final_context[:CTX_CHARS])
            # print("-" * 60)
            
            try:
                answer = chat_with_ax(messages)
                print("\nğŸ§¾ [A.X 4.0 ìµœì¢… ë‹µë³€]")
                print(extract_numbered_block(answer))
            except Exception as e:
                print(f"[ì˜¤ë¥˜] ìµœì¢… ë‹µë³€ ìƒì„± ì‹¤íŒ¨: {e}")