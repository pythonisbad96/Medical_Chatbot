import os
import json
import re
from langchain.embeddings import HuggingFaceEmbeddings
from langchain.vectorstores import FAISS
from openai import OpenAI
from rapidfuzz import fuzz

# âœ… ì„ë² ë”© ëª¨ë¸ ë¡œë“œ
embedding_model = HuggingFaceEmbeddings(model_name="jhgan/ko-sbert-sts")

# âœ… JSON íŒŒì¼ í´ë” ê²½ë¡œ
json_folder = "./json_diseases_final"

# âœ… í…ìŠ¤íŠ¸ ë°ì´í„° ì¶”ì¶œ í•¨ìˆ˜
def extract_text(field_dict):
    if not isinstance(field_dict, dict):
        return ""
    texts = []
    for v in field_dict.values():
        if isinstance(v, list):
            texts.append("\n".join(map(str, v)))
        elif isinstance(v, str):
            texts.append(v)
        else:
            texts.append(str(v))
    return "\n".join(texts)

# âœ… ë²¡í„° ì €ì¥ì†Œ êµ¬ì¶•
db_path = "vector_db/faiss_db_json"
os.makedirs("vector_db", exist_ok=True)
texts = []

for file in os.listdir(json_folder):
    if not file.endswith(".json"):
        continue
    with open(os.path.join(json_folder, file), encoding="utf-8") as f:
        data = json.load(f)

    disease_name = data.get("ë³‘ëª…", "")
    ì •ì˜ = extract_text(data.get("ì •ì˜", {}))
    ì›ì¸ = extract_text(data.get("ì›ì¸", {}))
    ì¦ìƒ = extract_text(data.get("ì¦ìƒ", {}))
    ì§„ë‹¨ = extract_text(data.get("ì§„ë‹¨", {}))
    ì¹˜ë£Œ = extract_text(data.get("ì¹˜ë£Œ", {}))

    full_text = f"""
[ë³‘ëª…] {disease_name}
[ì •ì˜] {ì •ì˜}
[ì›ì¸] {ì›ì¸}
[ì¦ìƒ] {ì¦ìƒ}
[ì§„ë‹¨] {ì§„ë‹¨}
[ì¹˜ë£Œ] {ì¹˜ë£Œ}
""".strip()

    if full_text:
        texts.append(full_text)

if not os.path.exists(db_path + "/index.faiss"):
    db = FAISS.from_texts(texts, embedding=embedding_model)
    db.save_local(db_path)

# âœ… ë²¡í„° DB ë¡œë“œ
db = FAISS.load_local(db_path, embedding_model, allow_dangerous_deserialization=True)

# âœ… SKT A.X-4.0 LLM
client = OpenAI(
    base_url="https://guest-api.sktax.chat/v1",
    api_key="sktax-XyeKFrq67ZjS4EpsDlrHHXV8it"
)

# âœ… ì‚¬ìš©ì ì…ë ¥ ë£¨í”„
while True:
    user_input = input("\nğŸ©º ì¦ìƒì„ ì…ë ¥í•˜ì„¸ìš” (ì¢…ë£Œ: exit): ")
    if user_input.lower() in ["exit", "ì¢…ë£Œ", "quit"]:
        print("ì±—ë´‡ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
        break

    # ğŸ” ìœ ì‚¬ ì§ˆë³‘ ê²€ìƒ‰
    docs = db.similarity_search(user_input, k=10)
    for i, doc in enumerate(docs[:3]):
        score = fuzz.token_sort_ratio(user_input, doc.page_content)
        print(f"{i+1}. ì ìˆ˜: {score} â†’ {doc.page_content[:100]}...\n")

    retrieved_context = "\n---\n".join([doc.page_content for doc in docs])[:600]

    # âœ… ê°œì„ ëœ í”„ë¡¬í”„íŠ¸
    prompt = f"""
ë‹¹ì‹ ì€ ì˜ë£Œ ìƒë‹´ ì±—ë´‡ì…ë‹ˆë‹¤.

ì‚¬ìš©ì ì§ˆë¬¸ì´ **ê±´ê°•/ì¦ìƒ/ì˜í•™ ê´€ë ¨ì´ë©´**, ì•„ë˜ [ì¦ìƒ ì •ë³´]ë¥¼ ì°¸ê³ í•˜ì—¬ 1~5ë²ˆ í•­ëª©ì„ ì‘ì„±í•˜ì„¸ìš”.  
**í•˜ì§€ë§Œ** ì§ˆë¬¸ì´ ìŒì‹, ì—¬í–‰, ìƒí™œ ìƒì‹ ë“± **ì˜ë£Œì™€ ë¬´ê´€í•œ ê²½ìš°**ì—ëŠ” [ì¦ìƒ ì •ë³´]ë¥¼ ë¬´ì‹œí•˜ê³  ììœ ë¡­ê²Œ ë‹µë³€í•˜ì„¸ìš”.  

í•­ìƒ ì¡´ëŒ“ë§(-ì…ë‹ˆë‹¤, -í•©ë‹ˆë‹¤)ë¡œ ë‹µë³€í•˜ë©°, ë‚´ë¶€ ìƒê° ì—†ì´ **ìµœì¢… ë‹µë³€ë§Œ ì¶œë ¥**í•˜ì„¸ìš”.

---

ğŸ§  ì§ˆë¬¸: {user_input}

---

[ì¦ìƒ ì •ë³´]
{retrieved_context}

---

ğŸ“ ì¶œë ¥ í˜•ì‹:
(ì˜ë£Œ ì§ˆë¬¸ì¼ ê²½ìš°)

1. ì˜ˆìƒë˜ëŠ” ë³‘ëª… (2~3ê°€ì§€):  
   - ì²« ë²ˆì§¸ ë³‘ëª…ì€ ê°„ë‹¨í•œ ì„¤ëª…ë„ í¬í•¨í•´ì£¼ì„¸ìš”.

2. ì£¼ìš” ì›ì¸:
3. ì¶”ì²œ ì§„ë£Œê³¼ (2~3ê³¼):
4. ì˜ˆë°© ë° ê´€ë¦¬ ë°©ë²•:
5. ìƒí™œ ì‹œ ì£¼ì˜ì‚¬í•­:

(ë¹„ì˜ë£Œ ì§ˆë¬¸ì¼ ê²½ìš°)

ë‹µë³€:
""".strip()

    # ğŸ§  ëª¨ë¸ í˜¸ì¶œ
    response = client.chat.completions.create(
        model="ax4",
        messages=[{"role": "user", "content": prompt}]
    )
    answer = response.choices[0].message.content.strip()

    # âœ… ì¶œë ¥ (RAG í˜•ì‹ì¼ ê²½ìš°ë§Œ 1~5 ì¶”ì¶œ)
    if "1." in answer and "2." in answer:
        match = re.search(r"1\..*?5\..*", answer, flags=re.DOTALL)
        answer_only = match.group().strip() if match else answer
        answer_only = re.sub(r"(ìŠµë‹ˆë‹¤|í•©ë‹ˆë‹¤)\1+", r"\1", answer_only)
    else:
        answer_only = answer.strip()

    print("\nğŸ§¾ [SKT A.X-4.0 ì‘ë‹µ ê²°ê³¼]")
    print(answer_only)
