{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "375b37e0",
   "metadata": {},
   "source": [
    "# ì…€ 1: ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸° ë° ì»¬ëŸ¼ëª… ë³€ê²½"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb3c45ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# í›ˆë ¨ ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "try:\n",
    "    train_df = pd.read_csv(\n",
    "        \"C:\\TP\\ëª¨ë¸í•™ìŠµ\\data\\symptom-disease-train-dataset-Translated.csv\",\n",
    "        encoding=\"utf-8\",\n",
    "    )\n",
    "except UnicodeDecodeError:\n",
    "    train_df = pd.read_csv(\n",
    "        \"C:\\TP\\ëª¨ë¸í•™ìŠµ\\data\\symptom-disease-train-dataset-Translated.csv\",\n",
    "        encoding=\"cp949\",\n",
    "    )\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "try:\n",
    "    test_df = pd.read_csv(\"C:\\TP\\ëª¨ë¸í•™ìŠµ\\data\\í•™ìŠµë°ì´í„°(ì¦ìƒ).csv\", encoding=\"utf-8\")\n",
    "except UnicodeDecodeError:\n",
    "    test_df = pd.read_csv(\"C:\\TP\\ëª¨ë¸í•™ìŠµ\\data\\í•™ìŠµë°ì´í„°(ì¦ìƒ).csv\", encoding=\"cp949\")\n",
    "\n",
    "# ì»¬ëŸ¼ëª… í†µì¼\n",
    "train_df = train_df.rename(columns={\"ë¼ë²¨\": \"label\", \"ì¦ìƒ_ë²ˆì—­\": \"text\"})\n",
    "test_df = test_df.rename(columns={\"ì¦ìƒ_ë²ˆì—­\": \"text\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff16222d",
   "metadata": {},
   "source": [
    "# ì…€ 2: LabelEncoderë¡œ ë¼ë²¨ í†µì¼ ì¸ì½”ë”©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49cd14b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# ë¬¸ìì—´ë¡œ ë³€í™˜í•˜ì—¬ í†µì¼\n",
    "train_df[\"label\"] = train_df[\"label\"].astype(str)\n",
    "test_df[\"label\"] = test_df[\"label\"].astype(str)\n",
    "\n",
    "# ì „ì²´ ë¼ë²¨ ê¸°ì¤€ìœ¼ë¡œ í•™ìŠµ\n",
    "all_labels = pd.concat([train_df[\"label\"], test_df[\"label\"]], axis=0)\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(all_labels)\n",
    "\n",
    "# ì¸ì½”ë”© ì ìš©\n",
    "train_df[\"label\"] = label_encoder.transform(train_df[\"label\"])\n",
    "test_df[\"label\"] = label_encoder.transform(test_df[\"label\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8328312",
   "metadata": {},
   "source": [
    "# ì…€ 3: ë¼ë²¨ í…ì„œë¡œ ë³€í™˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea4cc2db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_labels ìµœëŒ€ê°’: 865\n",
      "test_labels ìµœëŒ€ê°’: 889\n",
      "ì „ì²´ ë¼ë²¨ ìˆ˜: 890\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "train_labels = torch.tensor(train_df[\"label\"].tolist())\n",
    "test_labels = torch.tensor(test_df[\"label\"].tolist())\n",
    "\n",
    "print(\"train_labels ìµœëŒ€ê°’:\", train_labels.max().item())\n",
    "print(\"test_labels ìµœëŒ€ê°’:\", test_labels.max().item())\n",
    "print(\"ì „ì²´ ë¼ë²¨ ìˆ˜:\", len(label_encoder.classes_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d14eb4b",
   "metadata": {},
   "source": [
    "# ì…€ 4: í† í¬ë‚˜ì´ì € ë° ë°ì´í„°ì…‹ ì¤€ë¹„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f6b0b7e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\.pyenv\\pyenv-win\\versions\\3.11.9\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "model_name = \"beomi/KcELECTRA-base-v2022\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, texts, labels):\n",
    "        self.encodings = tokenizer(texts, truncation=True, padding=True, max_length=256)\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item[\"labels\"] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "\n",
    "train_dataset = TextDataset(train_df[\"text\"].tolist(), train_labels)\n",
    "test_dataset = TextDataset(test_df[\"text\"].tolist(), test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e28bcfa",
   "metadata": {},
   "source": [
    "# ì…€ 5: ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸° ë° í•™ìŠµ ì¤€ë¹„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b46f34d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output_path exists and is dir: True\n",
      "logging_path exists and is dir: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at beomi/KcELECTRA-base-v2022 and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "c:\\Users\\user\\.pyenv\\pyenv-win\\versions\\3.11.9\\Lib\\site-packages\\transformers\\training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ğŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "import os\n",
    "import shutil\n",
    "import torch\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# 1) model_outputê³¼ logs ê²½ë¡œ ì •ë¦¬\n",
    "output_path = os.path.abspath(\"C:/TP/model_output\")\n",
    "logging_path = os.path.join(output_path, \"logs\")\n",
    "\n",
    "if os.path.exists(output_path):\n",
    "    if os.path.isfile(output_path):\n",
    "        os.remove(output_path)\n",
    "    else:\n",
    "        shutil.rmtree(output_path)\n",
    "os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "if os.path.exists(logging_path):\n",
    "    if os.path.isfile(logging_path):\n",
    "        os.remove(logging_path)\n",
    "    else:\n",
    "        shutil.rmtree(logging_path)\n",
    "os.makedirs(logging_path, exist_ok=True)\n",
    "\n",
    "print(\"output_path exists and is dir:\", os.path.isdir(output_path))\n",
    "print(\"logging_path exists and is dir:\", os.path.isdir(logging_path))\n",
    "\n",
    "# 2) ëª¨ë¸ ìƒì„± (label_encoderì™€ model_nameì€ ì´ë¯¸ ì¤€ë¹„ëœ ìƒíƒœë¼ ê°€ì •)\n",
    "num_labels = len(label_encoder.classes_)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name, num_labels=num_labels\n",
    ")\n",
    "\n",
    "\n",
    "# 3) compute_metrics í•¨ìˆ˜ ì •ì˜\n",
    "def compute_metrics(p):\n",
    "    preds = torch.argmax(torch.tensor(p.predictions), dim=1)\n",
    "    labels = torch.tensor(p.label_ids)\n",
    "    acc = accuracy_score(labels.cpu(), preds.cpu())\n",
    "    return {\"accuracy\": acc}\n",
    "\n",
    "\n",
    "# 4) TrainingArguments ì„¤ì •\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=output_path,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_dir=logging_path,\n",
    "    logging_strategy=\"epoch\",  # ë¡œê·¸ ì €ì¥ì„ ë‹¤ì‹œ í™œì„±í™” (ë˜ëŠ” \"no\"ë¡œ ìœ ì§€ ê°€ëŠ¥)\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    greater_is_better=True,\n",
    ")\n",
    "\n",
    "# 5) Trainer ìƒì„±\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    compute_metrics=compute_metrics,  # âœ… ì—¬ê¸° ì¶”ê°€!\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fdb7c06",
   "metadata": {},
   "source": [
    "# ì…€ 6: ëª¨ë¸ í•™ìŠµ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3655cfb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\.pyenv\\pyenv-win\\versions\\3.11.9\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_26648\\3138785336.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item[\"labels\"] = torch.tensor(self.labels[idx])\n",
      "                                                  \n",
      " 33%|â–ˆâ–ˆâ–ˆâ–      | 353/1059 [1:13:11<41:53,  3.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 5.328, 'grad_norm': 16.07264518737793, 'learning_rate': 1.3333333333333333e-05, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "                                                    \n",
      "\n",
      "\u001b[A\u001b[A                                         \n",
      " 33%|â–ˆâ–ˆâ–ˆâ–      | 353/1059 [1:13:46<41:53,  3.56s/it]\n",
      "\u001b[A\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 7.335833549499512, 'eval_accuracy': 0.0, 'eval_runtime': 34.9574, 'eval_samples_per_second': 34.327, 'eval_steps_per_second': 2.145, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\.pyenv\\pyenv-win\\versions\\3.11.9\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_26648\\3138785336.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item[\"labels\"] = torch.tensor(self.labels[idx])\n",
      "                                                    \n",
      " 33%|â–ˆâ–ˆâ–ˆâ–      | 353/1059 [1:40:39<41:53,  3.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.28, 'grad_norm': 16.976343154907227, 'learning_rate': 6.666666666666667e-06, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "                                                    \n",
      "\u001b[A                                               \n",
      "\n",
      " 33%|â–ˆâ–ˆâ–ˆâ–      | 353/1059 [1:41:14<41:53,  3.56s/it]\n",
      "\u001b[A\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 7.191505432128906, 'eval_accuracy': 0.0, 'eval_runtime': 35.5775, 'eval_samples_per_second': 33.729, 'eval_steps_per_second': 2.108, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\.pyenv\\pyenv-win\\versions\\3.11.9\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_26648\\3138785336.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item[\"labels\"] = torch.tensor(self.labels[idx])\n",
      "                                                    \n",
      " 33%|â–ˆâ–ˆâ–ˆâ–      | 353/1059 [2:08:07<41:53,  3.56s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.529, 'grad_norm': 10.564023971557617, 'learning_rate': 0.0, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "                                                    \n",
      "\n",
      "\u001b[A\u001b[A                                         \n",
      " 33%|â–ˆâ–ˆâ–ˆâ–      | 353/1059 [2:08:43<41:53,  3.56s/it] \n",
      "\u001b[A\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 7.513923168182373, 'eval_accuracy': 0.0, 'eval_runtime': 36.2089, 'eval_samples_per_second': 33.141, 'eval_steps_per_second': 2.071, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                    \n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1059/1059 [1:22:30<00:00,  4.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 4950.8373, 'train_samples_per_second': 3.414, 'train_steps_per_second': 0.214, 'train_loss': 3.7123362367394064, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1059, training_loss=3.7123362367394064, metrics={'train_runtime': 4950.8373, 'train_samples_per_second': 3.414, 'train_steps_per_second': 0.214, 'total_flos': 2241279891154944.0, 'train_loss': 3.7123362367394064, 'epoch': 3.0})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1488fef6",
   "metadata": {},
   "source": [
    "# ì…€ 7: í…ŒìŠ¤íŠ¸ ë°ì´í„° ì˜ˆì¸¡ ë° ê²°ê³¼ í™•ì¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ddc0786f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\.pyenv\\pyenv-win\\versions\\3.11.9\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_26648\\3138785336.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item[\"labels\"] = torch.tensor(self.labels[idx])\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 75/75 [00:33<00:00,  2.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì…ë ¥: I have been experiencing a skin rash on my arms, legs, and torso for the past few weeks. It is red, itchy, and covered in dry, scaly patches.\n",
      "ì˜ˆì¸¡: 822 | ì‹¤ì œ: Psoriasis\n",
      "---\n",
      "ì…ë ¥: My skin has been peeling, especially on my knees, elbows, and scalp. This peeling is often accompanied by a burning or stinging sensation.\n",
      "ì˜ˆì¸¡: 822 | ì‹¤ì œ: Psoriasis\n",
      "---\n",
      "ì…ë ¥: I have been experiencing joint pain in my fingers, wrists, and knees. The pain is often achy and throbbing, and it gets worse when I move my joints.\n",
      "ì˜ˆì¸¡: 193 | ì‹¤ì œ: Psoriasis\n",
      "---\n",
      "ì…ë ¥: There is a silver like dusting on my skin, especially on my lower back and scalp. This dusting is made up of small scales that flake off easily when I scratch them.\n",
      "ì˜ˆì¸¡: 193 | ì‹¤ì œ: Psoriasis\n",
      "---\n",
      "ì…ë ¥: My nails have small dents or pits in them, and they often feel inflammatory and tender to the touch. Even there are minor rashes on my arms.\n",
      "ì˜ˆì¸¡: 394 | ì‹¤ì œ: Psoriasis\n",
      "---\n",
      "ì…ë ¥: The skin on my palms and soles is thickened and has deep cracks. These cracks are painful and bleed easily.\n",
      "ì˜ˆì¸¡: 822 | ì‹¤ì œ: Psoriasis\n",
      "---\n",
      "ì…ë ¥: The skin around my mouth, nose, and eyes is red and inflamed. It is often itchy and uncomfortable. There is a noticeable inflammation in my nails.\n",
      "ì˜ˆì¸¡: 193 | ì‹¤ì œ: Psoriasis\n",
      "---\n",
      "ì…ë ¥: My skin is very sensitive and reacts easily to changes in temperature or humidity. I often have to be careful about what products I use on my skin.\n",
      "ì˜ˆì¸¡: 186 | ì‹¤ì œ: Psoriasis\n",
      "---\n",
      "ì…ë ¥: I have noticed a sudden peeling of skin at different parts of my body, mainly arms, legs and back. Also, I face severe joint pain and skin rashes.\n",
      "ì˜ˆì¸¡: 822 | ì‹¤ì œ: Psoriasis\n",
      "---\n",
      "ì…ë ¥: The skin on my genitals is red and inflamed. It is often itchy, burning, and uncomfortable. There are rashes on different parts of the body too.\n",
      "ì˜ˆì¸¡: 193 | ì‹¤ì œ: Psoriasis\n",
      "---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "preds = trainer.predict(test_dataset)\n",
    "pred_labels = torch.argmax(torch.tensor(preds.predictions), dim=1)\n",
    "\n",
    "# ë””ì½”ë”©í•˜ì—¬ í™•ì¸\n",
    "decoded_preds = label_encoder.inverse_transform(pred_labels)\n",
    "decoded_targets = label_encoder.inverse_transform(test_labels)\n",
    "\n",
    "for i in range(10):\n",
    "    print(f\"ì…ë ¥: {test_df['text'].iloc[i]}\")\n",
    "    print(f\"ì˜ˆì¸¡: {decoded_preds[i]} | ì‹¤ì œ: {decoded_targets[i]}\")\n",
    "    print(\"---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2d748764",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\.pyenv\\pyenv-win\\versions\\3.11.9\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_26648\\3138785336.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item[\"labels\"] = torch.tensor(self.labels[idx])\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 75/75 [00:34<00:00,  2.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 7.335833549499512, 'eval_accuracy': 0.0, 'eval_runtime': 34.7436, 'eval_samples_per_second': 34.539, 'eval_steps_per_second': 2.159, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "eval_result = trainer.evaluate()\n",
    "print(eval_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8966ce08",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model(\"C:/TP/final_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "299547d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì˜ˆì¸¡ ê²°ê³¼: ['186']\n"
     ]
    }
   ],
   "source": [
    "test_texts = [\"ì—´ì´ ë‚˜ê³  ê¸°ì¹¨ì´ ì‹¬í•´ìš”\"]\n",
    "tokens = tokenizer(test_texts, truncation=True, padding=True, return_tensors=\"pt\")\n",
    "outputs = model(**tokens)\n",
    "preds = torch.argmax(outputs.logits, dim=1)\n",
    "print(\"ì˜ˆì¸¡ ê²°ê³¼:\", label_encoder.inverse_transform(preds.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f9679c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì˜ˆì¸¡ ë³‘ëª…: 186\n"
     ]
    }
   ],
   "source": [
    "test_texts = [\"ì—´ì´ ë‚˜ê³  ê¸°ì¹¨ì´ ì‹¬í•´ìš”\"]\n",
    "tokens = tokenizer(test_texts, truncation=True, padding=True, return_tensors=\"pt\")\n",
    "outputs = model(**tokens)\n",
    "preds = torch.argmax(outputs.logits, dim=1)\n",
    "\n",
    "# ì•ˆì „í•˜ê²Œ í´ë˜ìŠ¤ëª…ìœ¼ë¡œ ë””ì½”ë”©\n",
    "pred_label = label_encoder.classes_[preds.item()]\n",
    "print(\"ì˜ˆì¸¡ ë³‘ëª…:\", pred_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a39f7816",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    260\n",
       "1    300\n",
       "2    696\n",
       "3    115\n",
       "4    516\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[\"label\"].head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.11.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
